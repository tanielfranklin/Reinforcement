{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação DQN com prioritized replay no ambiente Swift com manipulador panda.\n",
    "\n",
    "Replay buffer <br>\n",
    "DNN para representar o agente atual e uma DNN alvo com uma taxa de atualização menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from IPython.display import clear_output\n",
    "from scipy.signal import convolve, gaussian\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import time\n",
    "import glob\n",
    "from IPython.display import HTML\n",
    "import data_panda as rbt\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#j3 range -0.08 a 3.75  #j2 range -0.07 a -3. #j1 range -1.8 a 1.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sistema observável e com medidas dos ângulos disponíveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Observation:\n",
    "        Type: Box(4)\n",
    "        Num     Observation               Min                     Max\n",
    "        0       Joint1                   -4.8                    4.8\n",
    "        1       Joint2                    -Inf                    Inf\n",
    "        2       Joint3                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "        \n",
    "    Actions:\n",
    "        Type: Discrete(9)\n",
    "        Num   Three actions for each joint\n",
    "        0     decrement joint j\n",
    "        1     increment joint j\n",
    "        2     decrement join  j\n",
    "\n",
    "        #j3 range 0.0 a 3.7\n",
    "        #j2 range 0.0 a -3.\n",
    "        #j1 range -1.7 a 1.7\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_shape = 3\n",
    "env=rbt.Panda_RL()\n",
    "agent=rbt.DQNAgent(state_shape, epsilon=0).to(device)\n",
    "env.renderize=True #stop robot viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERobot: panda (by Franka Emika), 7 joints (RRRRRRR), 1 gripper, geometry, collision\n",
       "┌─────┬──────────────┬───────┬─────────────┬────────────────────────────────────────────────┐\n",
       "│link │     link     │ joint │   parent    │              ETS: parent to link               │\n",
       "├─────┼──────────────┼───────┼─────────────┼────────────────────────────────────────────────┤\n",
       "│   0 │ panda_link0  │       │ BASE        │                                                │\n",
       "│   1 │ panda_link1  │     0 │ panda_link0 │ SE3(0, 0, 0.333) ⊕ Rz(q0)                      │\n",
       "│   2 │ panda_link2  │     1 │ panda_link1 │ SE3(-90°, -0°, 0°) ⊕ Rz(q1)                    │\n",
       "│   3 │ panda_link3  │     2 │ panda_link2 │ SE3(0, -0.316, 0; 90°, -0°, 0°) ⊕ Rz(q2)       │\n",
       "│   4 │ panda_link4  │     3 │ panda_link3 │ SE3(0.0825, 0, 0; 90°, -0°, 0°) ⊕ Rz(q3)       │\n",
       "│   5 │ panda_link5  │     4 │ panda_link4 │ SE3(-0.0825, 0.384, 0; -90°, -0°, 0°) ⊕ Rz(q4) │\n",
       "│   6 │ panda_link6  │     5 │ panda_link5 │ SE3(90°, -0°, 0°) ⊕ Rz(q5)                     │\n",
       "│   7 │ panda_link7  │     6 │ panda_link6 │ SE3(0.088, 0, 0; 90°, -0°, 0°) ⊕ Rz(q6)        │\n",
       "│   8 │ @panda_link8 │       │ panda_link7 │ SE3(0, 0, 0.107)                               │\n",
       "└─────┴──────────────┴───────┴─────────────┴────────────────────────────────────────────────┘\n",
       "\n",
       "┌─────┬─────┬────────┬─────┬───────┬─────┬───────┬──────┐\n",
       "│name │ q0  │ q1     │ q2  │ q3    │ q4  │ q5    │ q6   │\n",
       "├─────┼─────┼────────┼─────┼───────┼─────┼───────┼──────┤\n",
       "│  qr │  0° │ -17.2° │  0° │ -126° │  0° │  115° │  45° │\n",
       "│  qz │  0° │  0°    │  0° │  0°   │  0° │  0°   │  0°  │\n",
       "└─────┴─────┴────────┴─────┴───────┴─────┴───────┴──────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.panda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.renderize=True\n",
    "# env.scene.start_recording(\"video\",10.)\n",
    "# final_score,m_steps,infos = rbt.evaluate(env,agent, n_games=1, greedy=True, t_max=300)\n",
    "# env.scene.stop_recording()\n",
    "# print(f'final score:{final_score} in {m_steps} steps')\n",
    "# print(infos)\n",
    "# print(f'Well done , Distance: {env.distance()}, Fitness: {env.fitness()}')\n",
    "# print(f\"collision {env.detect_collision()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intializinf from predefined state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score:4721.951234042601 in 572 steps\n",
      "Status: Done Completed\n"
     ]
    }
   ],
   "source": [
    "q_far=np.array([ 0., -0.8 ,  0. , -0.0698,  0.,  3.3825,  0.    ])\n",
    "agent.play(env,\"results_8\",tmax=800,q0=q_far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.play(env,\"results_8\",tmax=800,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.scene._send_socket(\"stop_recording\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must call swift.start_recording(file_name) before trying to stop the recording",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# env.scene.start_recording(\"video.webm\",1)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# agent.play(env,\"results_8\",tmax=800)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m env\u001b[39m.\u001b[39;49mscene\u001b[39m.\u001b[39;49mstop_recording()\n",
      "File \u001b[0;32m~/anaconda3/envs/RTB/lib/python3.10/site-packages/swift/Swift.py:490\u001b[0m, in \u001b[0;36mSwift.stop_recording\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send_socket(\u001b[39m\"\u001b[39m\u001b[39mstop_recording\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    489\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 490\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    491\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou must call swift.start_recording(file_name) before trying\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    492\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m to stop the recording\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    493\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: You must call swift.start_recording(file_name) before trying to stop the recording"
     ]
    }
   ],
   "source": [
    "# env.scene.start_recording(\"video.webm\",1)\n",
    "# agent.play(env,\"results_8\",tmax=800)\n",
    "env.scene.stop_recording()\n",
    "#(env, DIR,tmax=300,model=\"best\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us record a video of trained agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Animate learned policy\n",
    "# save_dir='./videos/'\n",
    "# #env = make_env(env_name)\n",
    "# generate_animation(env, agent, save_dir=save_dir)\n",
    "# [filepath] = glob.glob(os.path.join(save_dir, '*.mp4'))\n",
    "\n",
    "# display_animation(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "# Run this on another environment in OpenAI Gym\n",
    "# Create a robotic environment with more actions\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('RTB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "007c3d4ec7d1faff975b7b2e6628fd4907f6779597816faa5595ad19bf6f4797"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
