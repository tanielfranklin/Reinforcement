{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação DQN com prioritized replay no ambiente Swift com manipulador panda.\n",
    "\n",
    "Replay buffer <br>\n",
    "DNN para representar o agente atual e uma DNN alvo com uma taxa de atualização menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from IPython.display import clear_output\n",
    "from scipy.signal import convolve, gaussian\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import time\n",
    "import glob\n",
    "from IPython.display import HTML\n",
    "import data_panda as rbt\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#j3 range -0.08 a 3.75  #j2 range -0.07 a -3. #j1 range -1.8 a 1.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sistema observável e com medidas dos ângulos disponíveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Observation:\n",
    "        Type: Box(4)\n",
    "        Num     Observation               Min                     Max\n",
    "        0       Joint1                   -4.8                    4.8\n",
    "        1       Joint2                    -Inf                    Inf\n",
    "        2       Joint3                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "        \n",
    "    Actions:\n",
    "        Type: Discrete(9)\n",
    "        Num   Three actions for each joint\n",
    "        0     decrement joint j\n",
    "        1     increment joint j\n",
    "        2     decrement join  j\n",
    "\n",
    "        #j3 range 0.0 a 3.7\n",
    "        #j2 range 0.0 a -3.\n",
    "        #j1 range -1.7 a 1.7\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.panda = rp.models.Panda()\n",
    "# self.panda_end = rp.models.Panda()\n",
    "# self.m=100 #magnification factor\n",
    "\n",
    "# self.obstacle = Cuboid([0.2, 0.2, 0.8], pose=sm.SE3(0.3, 0, 0)) \n",
    "# #self.floor = Cuboid([0.2, 0.2, 0.8], pose=sm.SE3(-0.2, 0, 0)) \n",
    "# self.obs_floor = Cuboid([2., 2., 0.01], pose=sm.SE3(0, 0, 0), color=[100,100,100,0])#\"black\") #color=[100,100,100,0]\n",
    "# self.scene.add(self.obs_floor)\n",
    "# self.scene.add(self.obstacle)\n",
    "# self.scene.add(self.panda, robot_alpha=0.6)\n",
    "# self.delta=delta\n",
    "# #End joints positions\n",
    "# j=[0.8,-1.5,1] \n",
    "# self.q_end=[0., j[0], 0.,j[1], 0., j[2], 0.]\n",
    "# self.Tep = self.panda.fkine(self.q_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_shape = 3\n",
    "env=rbt.Panda_RL()\n",
    "agent=rbt.DQNAgent(state_shape, epsilon=0).to(device)\n",
    "env.delta=0.02\n",
    "RESTORE_AGENT=False # Restore a trained agent\n",
    "NEW_BUFFER=True # Restore a buffer\n",
    "TRAIN=True # Train or only simulate\n",
    "env.renderize=True #stop robot viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERobot: panda (by Franka Emika), 7 joints (RRRRRRR), 1 gripper, geometry, collision\n",
       "┌─────┬──────────────┬───────┬─────────────┬────────────────────────────────────────────────┐\n",
       "│link │     link     │ joint │   parent    │              ETS: parent to link               │\n",
       "├─────┼──────────────┼───────┼─────────────┼────────────────────────────────────────────────┤\n",
       "│   0 │ panda_link0  │       │ BASE        │                                                │\n",
       "│   1 │ panda_link1  │     0 │ panda_link0 │ SE3(0, 0, 0.333) ⊕ Rz(q0)                      │\n",
       "│   2 │ panda_link2  │     1 │ panda_link1 │ SE3(-90°, -0°, 0°) ⊕ Rz(q1)                    │\n",
       "│   3 │ panda_link3  │     2 │ panda_link2 │ SE3(0, -0.316, 0; 90°, -0°, 0°) ⊕ Rz(q2)       │\n",
       "│   4 │ panda_link4  │     3 │ panda_link3 │ SE3(0.0825, 0, 0; 90°, -0°, 0°) ⊕ Rz(q3)       │\n",
       "│   5 │ panda_link5  │     4 │ panda_link4 │ SE3(-0.0825, 0.384, 0; -90°, -0°, 0°) ⊕ Rz(q4) │\n",
       "│   6 │ panda_link6  │     5 │ panda_link5 │ SE3(90°, -0°, 0°) ⊕ Rz(q5)                     │\n",
       "│   7 │ panda_link7  │     6 │ panda_link6 │ SE3(0.088, 0, 0; 90°, -0°, 0°) ⊕ Rz(q6)        │\n",
       "│   8 │ @panda_link8 │       │ panda_link7 │ SE3(0, 0, 0.107)                               │\n",
       "└─────┴──────────────┴───────┴─────────────┴────────────────────────────────────────────────┘\n",
       "\n",
       "┌─────┬─────┬────────┬─────┬───────┬─────┬───────┬──────┐\n",
       "│name │ q0  │ q1     │ q2  │ q3    │ q4  │ q5    │ q6   │\n",
       "├─────┼─────┼────────┼─────┼───────┼─────┼───────┼──────┤\n",
       "│  qr │  0° │ -17.2° │  0° │ -126° │  0° │  115° │  45° │\n",
       "│  qz │  0° │  0°    │  0° │  0°   │  0° │  0°   │  0°  │\n",
       "└─────┴─────┴────────┴─────┴───────┴─────┴───────┴──────┘"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if RESTORE_AGENT:\n",
    "    percentage_of_total_steps=0.1\n",
    "    agent.load_state_dict(torch.load('model_panda_trained_prio.pth'))\n",
    "    with open('td_loss_history.pickle', 'rb') as handle:\n",
    "        td_loss_history=pickle.load(handle)\n",
    "    with open('mean_rw_history.pickle', 'rb') as handle:\n",
    "        mean_rw_history=pickle.load(handle)\n",
    "else:\n",
    "    percentage_of_total_steps=0.9\n",
    "    mean_rw_history = []\n",
    "    td_loss_history = []\n",
    "\n",
    "env.panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_network = rbt.DQNAgent(agent.state_shape, epsilon=0.5).to(device)\n",
    "#Copying weights from agent network\n",
    "target_network.load_state_dict(agent.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8d105c66f0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.panda.q=env.panda.qz\n",
    "# set a seed\n",
    "seed = 13\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.342661864180592 10.28177829\n"
     ]
    }
   ],
   "source": [
    "q_far=np.array([ 0., -0.8 ,  0. , -0.0698,  0.,  3.3825,  0.    ])\n",
    "env.panda.q=q_far\n",
    "env.scene.step()\n",
    "print(env.distance(),env.fitness())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6138186274239739 3.68547204\n"
     ]
    }
   ],
   "source": [
    "env.panda.q=env.panda.qz\n",
    "env.scene.step()\n",
    "print(env.distance(),env.fitness())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6141983869955122 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   0.1892    0.1892   -0.9636    0.4463    \n",
       "   0.7071   -0.7071    0         0         \n",
       "  -0.6813   -0.6813   -0.2675    0.1586    \n",
       "   0         0         0         1         \n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.panda.q=env.q_goal\n",
    "env.scene.step()\n",
    "print(env.distance(),env.fitness())\n",
    "T_end=env.panda.fkine(env.q_goal)\n",
    "T_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of result directories: 0\n",
      "results_1\n"
     ]
    }
   ],
   "source": [
    "def set_res_dir():\n",
    "    # Directory to store results\n",
    "    res_dir_count = len(glob.glob('runs/train/*'))\n",
    "    print(f\"Current number of result directories: {res_dir_count}\")\n",
    "    if TRAIN:\n",
    "        RES_DIR = f\"results_{res_dir_count+1}\"\n",
    "        print(RES_DIR)\n",
    "    else:\n",
    "        RES_DIR = f\"results_{res_dir_count}\"\n",
    "    return RES_DIR\n",
    "\n",
    "RES_DIR = set_res_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8    -0.0898  3.3825] -20.706958338579007 10.22497029\n",
      "[-0.8    -0.1098  3.3825] 10.594302298524505 10.16896229\n",
      "[-0.8    -0.1298  3.3825] 10.592655421741416 10.11375429\n",
      "[-0.8    -0.1498  3.3825] 10.590960121062551 10.05934629\n",
      "[-0.8    -0.1698  3.3825] 10.589214228976132 10.00573829\n",
      "[-0.8    -0.1898  3.3825] 10.587415446656772 9.952930290000001\n",
      "[-0.8    -0.2098  3.3825] 10.58556133386899 9.90092229\n",
      "[-0.8    -0.2298  3.3825] 10.583649297924485 9.84971429\n",
      "[-0.8    -0.2498  3.3825] 10.581676581588384 9.79930629\n",
      "[-0.8    -0.2698  3.3825] 10.579640249815707 9.74969829\n",
      "[-0.8    -0.2898  3.3825] 10.577537175183869 9.70089029\n",
      "[-0.8    -0.3098  3.3825] 10.575364021869365 9.65288229\n",
      "[-0.8    -0.3298  3.3825] 10.573117227995795 9.60567429\n",
      "[-0.8    -0.3498  3.3825] 10.570792986156928 9.55926629\n",
      "[-0.8    -0.3698  3.3825] 10.568387221890873 9.51365829\n",
      "[-0.8    -0.3898  3.3825] 10.56589556984926 9.468850289999999\n",
      "[-0.8    -0.4098  3.3825] 10.563313347368386 9.42484229\n",
      "[-0.8    -0.4298  3.3825] 10.560635525105905 9.381634290000001\n",
      "[-0.8    -0.4498  3.3825] 10.55785669435544 9.33922629\n",
      "[-0.8    -0.4698  3.3825] 10.55497103059264 9.297618289999999\n",
      "[-0.8    -0.4898  3.3825] 10.551972252735647 9.25681029\n",
      "[-0.8    -0.5098  3.3825] 10.54885357752051 9.21680229\n",
      "[-0.8    -0.5298  3.3825] 10.545607668294238 9.17759429\n",
      "[-0.8    -0.5498  3.3825] 10.542226577412318 9.13918629\n",
      "[-0.8    -0.5698  3.3825] 10.5387016812888 9.101578289999999\n",
      "[-0.8    -0.5898  3.3825] 10.535023606982099 9.06477029\n",
      "[-0.8    -0.6098  3.3825] 10.531182149001157 9.02876229\n",
      "[-0.8    -0.6298  3.3825] 10.527166174777552 8.993554289999999\n",
      "[-0.8    -0.6498  3.3825] 10.522963516960752 8.95914629\n",
      "[-0.8    -0.6698  3.3825] 10.518560850342638 8.925538289999999\n",
      "[-0.8    -0.6898  3.3825] 10.513943550790001 8.89273029\n",
      "[-0.8    -0.7098  3.3825] 10.509095533040693 8.86072229\n",
      "[-0.8    -0.7298  3.3825] 10.503999063573977 8.829514289999999\n",
      "[-0.8    -0.7498  3.3825] 10.498634543970077 8.79910629\n",
      "[-0.8    -0.7698  3.3825] 10.492980259183556 8.76949829\n",
      "[-0.8    -0.7898  3.3825] 10.48701208391789 8.74069029\n",
      "[-0.8    -0.8098  3.3825] 10.480703138734865 8.71268229\n",
      "[-0.8    -0.8298  3.3825] 10.474023385566579 8.68547429\n",
      "[-0.8    -0.8498  3.3825] 10.46693914979807 8.65906629\n",
      "[-0.8    -0.8698  3.3825] 10.459412552887004 8.63345829\n",
      "[-0.8    -0.8898  3.3825] 10.451400835357411 8.60865029\n",
      "[-0.8    -0.9098  3.3825] 10.442855544639997 8.58464229\n",
      "[-0.8    -0.9298  3.3825] 10.433721555205508 8.56143429\n",
      "[-0.8    -0.9498  3.3825] 10.423935879160148 8.539026289999999\n",
      "[-0.8    -0.9698  3.3825] 10.413426213110299 8.51741829\n",
      "[-0.8    -0.9898  3.3825] 10.402109150476795 8.49661029\n",
      "[-0.8    -1.0098  3.3825] 10.389887965844629 8.476602289999999\n",
      "[-0.8    -1.0298  3.3825] 10.376649846899346 8.45739429\n",
      "[-0.8    -1.0498  3.3825] 10.362262406365247 8.438986289999999\n",
      "[-0.8    -1.0698  3.3825] 10.34656924565338 8.42137829\n",
      "[-0.8    -1.0898  3.3825] 10.329384255319479 8.404570289999999\n",
      "[-0.8    -1.1098  3.3825] 10.310484212035435 8.38856229\n",
      "[-0.8    -1.1298  3.3825] 10.289599047307904 8.37335429\n",
      "[-0.8    -1.1498  3.3825] 10.266398887001936 8.358946289999999\n",
      "[-0.8    -1.1698  3.3825] 10.240476539296932 8.34533829\n",
      "[-0.8    -1.1898  3.3825] 10.21132345191537 8.33253029\n",
      "[-0.8    -1.2098  3.3825] 10.17829611177191 8.32052229\n",
      "[-0.8    -1.2298  3.3825] 10.140568145102444 8.30931429\n",
      "[-0.8    -1.2498  3.3825] 10.097060485885137 8.29890629\n",
      "[-0.8    -1.2698  3.3825] 10.046336948100238 8.28929829\n",
      "[-0.8    -1.2898  3.3825] 9.98644344430849 8.28049029\n",
      "[-0.8    -1.3098  3.3825] 9.914651948396195 8.27248229\n",
      "[-0.8    -1.3298  3.3825] 9.827036342056294 8.26527429\n",
      "[-0.8    -1.3498  3.3825] 9.717736022069225 8.25886629\n",
      "[-0.8    -1.3698  3.3825] 9.5776029510874 8.25325829\n",
      "[-0.8    -1.3898  3.3825] 9.391536438218369 8.248450290000001\n",
      "[-0.8    -1.4098  3.3825] 9.132749783144716 8.24444229\n",
      "[-0.8    -1.4298  3.3825] 8.748939424204085 8.24123429\n",
      "[-0.8    -1.4498  3.3825] 8.123328235709407 8.23882629\n",
      "[-0.8    -1.4698  3.3825] 6.938226625625575 8.23721829\n",
      "[-0.8    -1.4898  3.3825] 4.034797214593805 8.23641029\n",
      "[-0.8    -1.5098  3.3825] -4.874342907912445 8.236402290000001\n",
      "[-0.8    -1.5298  3.3825] -13.937348000382825 8.23719429\n",
      "[-0.8    -1.5498  3.3825] -16.903875468645207 8.23878629\n",
      "[-0.8    -1.5698  3.3825] -18.10680667463693 8.24117829\n",
      "[-0.8    -1.5898  3.3825] -18.739370892462457 8.24437029\n",
      "[-0.8    -1.6098  3.3825] -19.126540835874096 8.24836229\n",
      "[-0.8    -1.6298  3.3825] -19.387191878689432 8.253154290000001\n",
      "[-0.8    -1.6498  3.3825] -19.57439632579927 8.258746290000001\n",
      "[-0.8    -1.6698  3.3825] -19.715273587209083 8.26513829\n",
      "[-0.8    -1.6898  3.3825] -19.825086706073588 8.272330290000001\n",
      "[-0.8    -1.7098  3.3825] -19.913070412589455 8.28032229\n",
      "[-0.8    -1.7298  3.3825] -19.985134961115314 8.28911429\n",
      "[-0.8    -1.7498  3.3825] -20.045236543840815 8.29870629\n",
      "[-0.8    -1.7698  3.3825] -20.096122255735715 8.309098290000001\n",
      "[-0.8    -1.7898  3.3825] -20.13975874477111 8.32029029\n",
      "[-0.8    -1.8098  3.3825] -20.17759074140591 8.332282290000002\n",
      "[-0.8    -1.8298  3.3825] -20.210703286756182 8.345074290000001\n",
      "[-0.8    -1.8498  3.3825] -20.239927034038804 8.35866629\n",
      "[-0.8    -1.8698  3.3825] -20.265908626104853 8.373058290000001\n",
      "[-0.8    -1.8898  3.3825] -20.28915894678139 8.388250290000002\n",
      "[-0.8    -1.9098  3.3825] -20.310086953495862 8.404242290000001\n",
      "[-0.8    -1.9298  3.3825] -20.32902387716317 8.421034290000001\n",
      "[-0.8    -1.9498  3.3825] -20.346240842735437 8.438626290000002\n",
      "[-0.78   -1.9498  3.3825] 10.60786916235022 8.375026290000001\n",
      "[-0.76   -1.9498  3.3825] 10.606594165000542 8.312226290000002\n",
      "[-0.74   -1.9498  3.3825] 10.605286267918366 8.25022629\n",
      "[-0.72   -1.9498  3.3825] 10.603944181100665 8.189026290000001\n",
      "[-0.7    -1.9498  3.3825] 10.602566546212252 8.128626290000001\n",
      "[-0.68   -1.9498  3.3825] 10.601151932000672 8.06902629\n",
      "[-0.66   -1.9498  3.3825] 10.599698829337003 8.01022629\n",
      "[-0.64   -1.9498  3.3825] 10.59820564584632 7.9522262900000005\n",
      "[-0.62   -1.9498  3.3825] 10.596670700087685 7.895026290000001\n",
      "[-0.6    -1.9498  3.3825] 10.595092215238944 7.8386262900000006\n",
      "[-0.58   -1.9498  3.3825] 10.593468312236533 7.7830262900000005\n",
      "[-0.56   -1.9498  3.3825] 10.59179700231454 7.72822629\n",
      "[-0.54   -1.9498  3.3825] 10.590076178880775 7.67422629\n",
      "[-0.52   -1.9498  3.3825] 10.588303608660098 7.6210262900000005\n",
      "[-0.5    -1.9498  3.3825] 10.586476922026742 7.56862629\n",
      "[-0.48   -1.9498  3.3825] 10.584593602437547 7.51702629\n",
      "[-0.46   -1.9498  3.3825] 10.58265097486721 7.46622629\n",
      "[-0.44   -1.9498  3.3825] 10.580646193133633 7.41622629\n",
      "[-0.42   -1.9498  3.3825] 10.578576225987247 7.36702629\n",
      "[-0.4    -1.9498  3.3825] 10.576437841821228 7.31862629\n",
      "[-0.38   -1.9498  3.3825] 10.574227591840577 7.27102629\n",
      "[-0.36   -1.9498  3.3825] 10.571941791505584 7.22422629\n",
      "[-0.34   -1.9498  3.3825] 10.569576500039846 7.17822629\n",
      "[-0.32   -1.9498  3.3825] 10.567127497763062 7.13302629\n",
      "[-0.3    -1.9498  3.3825] 10.564590260974459 7.0886262900000006\n",
      "[-0.28   -1.9498  3.3825] 10.56195993407237 7.04502629\n",
      "[-0.26   -1.9498  3.3825] 10.559231298548584 7.00222629\n",
      "[-0.24   -1.9498  3.3825] 10.556398738441022 6.96022629\n",
      "[-0.22   -1.9498  3.3825] 10.553456201763517 6.91902629\n",
      "[-0.2    -1.9498  3.3825] 10.550397157355606 6.87862629\n",
      "[-0.18   -1.9498  3.3825] 10.547214546504897 6.8390262900000005\n",
      "[-0.16   -1.9498  3.3825] 10.54390072858817 6.80022629\n",
      "[-0.14   -1.9498  3.3825] 10.54044741985026 6.76222629\n",
      "[-0.12   -1.9498  3.3825] 10.536845624288606 6.725026290000001\n",
      "[-0.1    -1.9498  3.3825] 10.533085555429745 6.68862629\n",
      "[-0.08   -1.9498  3.3825] 10.529156547566142 6.653026290000001\n",
      "[-0.06   -1.9498  3.3825] 10.525046954758938 6.61822629\n",
      "[-0.04   -1.9498  3.3825] 10.520744035592971 6.58422629\n",
      "[-0.02   -1.9498  3.3825] 10.516233821283445 6.55102629\n",
      "[ 3.95516953e-16 -1.94980000e+00  3.38250000e+00] 10.511500964259085 6.51862629\n",
      "[ 0.02   -1.9498  3.3825] 10.506528563765663 6.48702629\n",
      "[ 0.04   -1.9498  3.3825] 10.501297964316 6.45622629\n",
      "[ 0.06   -1.9498  3.3825] 10.495788521923421 6.426226290000001\n",
      "[ 0.08   -1.9498  3.3825] 10.489977331947335 6.39702629\n",
      "[ 0.1    -1.9498  3.3825] 10.48383891099066 6.36862629\n",
      "[ 0.12   -1.9498  3.3825] 10.477344823538521 6.34102629\n",
      "[ 0.14   -1.9498  3.3825] 10.47046324180727 6.314226290000001\n",
      "[ 0.16   -1.9498  3.3825] 10.463158424439163 6.288226290000001\n",
      "[ 0.18   -1.9498  3.3825] 10.455390096036316 6.263026290000001\n",
      "[ 0.2    -1.9498  3.3825] 10.44711270481285 6.238626290000001\n",
      "[ 0.22   -1.9498  3.3825] 10.438274529494517 6.215026290000001\n",
      "[ 0.24   -1.9498  3.3825] 10.428816598507867 6.192226290000001\n",
      "[ 0.26   -1.9498  3.3825] 10.4186713737732 6.1702262900000004\n",
      "[ 0.28   -1.9498  3.3825] 10.407761137054127 6.14902629\n",
      "[ 0.3    -1.9498  3.3825] 10.395995997400092 6.128626290000001\n",
      "[ 0.32   -1.9498  3.3825] 10.3832714116912 6.109026290000001\n",
      "[ 0.34   -1.9498  3.3825] 10.369465073640555 6.09022629\n",
      "[ 0.36   -1.9498  3.3825] 10.354432975345953 6.072226290000001\n",
      "[ 0.38   -1.9498  3.3825] 10.33800437284212 6.055026290000001\n",
      "[ 0.4    -1.9498  3.3825] 10.319975282705489 6.038626290000001\n",
      "[ 0.4    -1.9498  3.3625] 10.64088105267054 5.94372629\n",
      "[ 0.4    -1.9498  3.3425] 10.640310764236245 5.84962629\n",
      "[ 0.4    -1.9498  3.3225] 10.639730696387444 5.7563262900000005\n",
      "[ 0.4    -1.9498  3.3025] 10.639140595403799 5.66382629\n",
      "[ 0.4    -1.9498  3.2825] 10.638540198711741 5.57212629\n",
      "[ 0.4    -1.9498  3.2625] 10.637929234494932 5.4812262899999995\n",
      "[ 0.4    -1.9498  3.2425] 10.637307421283968 5.39112629\n",
      "[ 0.4    -1.9498  3.2225] 10.636674467524038 5.30182629\n",
      "[ 0.4    -1.9498  3.2025] 10.636030071119125 5.2133262899999995\n",
      "[ 0.4    -1.9498  3.1825] 10.635373918951272 5.12562629\n",
      "[ 0.4    -1.9498  3.1625] 10.634705686373307 5.03872629\n",
      "[ 0.4    -1.9498  3.1425] 10.634025036673272 4.9526262899999995\n",
      "[ 0.4    -1.9498  3.1225] 10.633331620508722 4.867326289999999\n",
      "[ 0.4    -1.9498  3.1025] 10.632625075308905 4.782826289999999\n",
      "[ 0.4    -1.9498  3.0825] 10.631905024642665 4.69912629\n",
      "[ 0.4    -1.9498  3.0625] 10.63117107754972 4.616226289999999\n",
      "[ 0.4    -1.9498  3.0425] 10.630422827832884 4.534126289999999\n",
      "[ 0.4    -1.9498  3.0225] 10.629659853308501 4.452826289999999\n",
      "[ 0.4    -1.9498  3.0025] 10.628881715012168 4.372326289999999\n",
      "[ 0.4    -1.9498  2.9825] 10.628087956356655 4.2926262899999985\n",
      "[ 0.4    -1.9498  2.9625] 10.627278102238584 4.2137262899999985\n",
      "[ 0.4    -1.9498  2.9425] 10.626451658090229 4.1356262899999985\n",
      "[ 0.4    -1.9498  2.9225] 10.62560810887243 4.058326289999998\n",
      "[ 0.4    -1.9498  2.9025] 10.624746918004352 3.981826289999999\n",
      "[ 0.4    -1.9498  2.8825] 10.623867526225357 3.9061262899999987\n",
      "[ 0.4    -1.9498  2.8625] 10.622969350383983 3.8312262899999983\n",
      "[ 0.4    -1.9498  2.8425] 10.622051782148464 3.7571262899999986\n",
      "[ 0.4    -1.9498  2.8225] 10.621114186632862 3.683826289999998\n",
      "[ 0.4    -1.9498  2.8025] 10.620155900932193 3.6113262899999983\n",
      "[ 0.4    -1.9498  2.7825] 10.619176232559566 3.5396262899999984\n",
      "[ 0.4    -1.9498  2.7625] 10.6181744577775 3.4687262899999984\n",
      "[ 0.4    -1.9498  2.7425] 10.617149819815008 3.3986262899999984\n",
      "[ 0.4    -1.9498  2.7225] 10.616101526961224 3.3293262899999982\n",
      "[ 0.4    -1.9498  2.7025] 10.61502875052544 3.260826289999998\n",
      "[ 0.4    -1.9498  2.6825] 10.613930622652575 3.1931262899999986\n",
      "[ 0.4    -1.9498  2.6625] 10.612806233981924 3.126226289999998\n",
      "[ 0.4    -1.9498  2.6425] 10.611654631135899 3.0601262899999986\n",
      "[ 0.4    -1.9498  2.6225] 10.610474814024268 2.994826289999998\n",
      "[ 0.4    -1.9498  2.6025] 10.609265732947776 2.9303262899999982\n",
      "[ 0.4    -1.9498  2.5825] 10.608026285483591 2.8666262899999984\n",
      "[ 0.4    -1.9498  2.5625] 10.606755313133116 2.8037262899999984\n",
      "[ 0.4    -1.9498  2.5425] 10.605451597710756 2.7416262899999984\n",
      "[ 0.4    -1.9498  2.5225] 10.604113857449992 2.6803262899999982\n",
      "[ 0.4    -1.9498  2.5025] 10.602740742800584 2.619826289999998\n",
      "[ 0.4    -1.9498  2.4825] 10.601330831887942 2.5601262899999977\n",
      "[ 0.4    -1.9498  2.4625] 10.599882625602572 2.501226289999998\n",
      "[ 0.4    -1.9498  2.4425] 10.59839454228393 2.4431262899999977\n",
      "[ 0.4    -1.9498  2.4225] 10.59686491195907 2.385826289999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taniel/anaconda3/envs/RTB/lib/python3.10/site-packages/roboticstoolbox/robot/Link.py:1041: FutureWarning: base kwarg is deprecated, use pose instead\n",
      "  warn(\"base kwarg is deprecated, use pose instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4    -1.9498  2.4025] 10.59529197009198 2.3293262899999982\n",
      "[ 0.4    -1.9498  2.3825] 10.593673850794403 2.273626289999998\n",
      "[ 0.4    -1.9498  2.3625] 10.59200857944326 2.218726289999998\n",
      "[ 0.4    -1.9498  2.3425] 10.590294064643249 2.164626289999998\n",
      "[ 0.4    -1.9498  2.3225] 10.588528089465875 2.111326289999998\n",
      "[ 0.4    -1.9498  2.3025] 10.586708301887711 2.058826289999998\n",
      "[ 0.4    -1.9498  2.2825] 10.584832204341248 2.0071262899999978\n",
      "[ 0.4    -1.9498  2.2625] 10.582897142280672 1.956226289999998\n",
      "[ 0.4    -1.9498  2.2425] 10.580900291652588 1.906126289999998\n",
      "[ 0.4    -1.9498  2.2225] 10.578838645147252 1.8568262899999979\n",
      "[ 0.4    -1.9498  2.2025] 10.576708997089664 1.808326289999998\n",
      "[ 0.4    -1.9498  2.1825] 10.574507926810854 1.760626289999998\n",
      "[ 0.4    -1.9498  2.1625] 10.572231780317999 1.7137262899999979\n",
      "[ 0.4    -1.9498  2.1425] 10.5698766500568 1.667626289999998\n",
      "[ 0.4    -1.9498  2.1225] 10.56743835253043 1.622326289999998\n",
      "[ 0.4    -1.9498  2.1025] 10.564912403505431 1.577826289999998\n",
      "[ 0.4    -1.9498  2.0825] 10.562293990495519 1.534126289999998\n",
      "[ 0.4    -1.9498  2.0625] 10.559577942168143 1.491226289999998\n",
      "[ 0.4    -1.9498  2.0425] 10.556758694264733 1.449126289999998\n",
      "[ 0.4    -1.9498  2.0225] 10.553830251562168 1.407826289999998\n",
      "[ 0.4    -1.9498  2.0025] 10.550786145328443 1.367326289999998\n",
      "[ 0.4    -1.9498  1.9825] 10.547619385637345 1.3276262899999982\n",
      "[ 0.4    -1.9498  1.9625] 10.544322407802547 1.288726289999998\n",
      "[ 0.4    -1.9498  1.9425] 10.540887012067374 1.2506262899999983\n",
      "[ 0.4    -1.9498  1.9225] 10.537304295538476 1.2133262899999981\n",
      "[ 0.4    -1.9498  1.9025] 10.533564575174204 1.1768262899999982\n",
      "[ 0.4    -1.9498  1.8825] 10.529657300425763 1.141126289999998\n",
      "[ 0.4    -1.9498  1.8625] 10.525570953872116 1.1062262899999982\n",
      "[ 0.4    -1.9498  1.8425] 10.521292937878648 1.0721262899999981\n",
      "[ 0.4    -1.9498  1.8225] 10.516809444931358 1.0388262899999983\n",
      "[ 0.4    -1.9498  1.8025] 10.512105308836446 1.0063262899999983\n",
      "[ 0.4    -1.9498  1.7825] 10.507163833408299 0.9746262899999983\n",
      "[ 0.4    -1.9498  1.7625] 10.501966594570469 0.9437262899999984\n",
      "[ 0.4    -1.9498  1.7425] 10.49649321092854 0.9136262899999984\n",
      "[ 0.4    -1.9498  1.7225] 10.490721076796039 0.8843262899999985\n",
      "[ 0.4    -1.9498  1.7025] 10.484625050304706 0.8558262899999985\n",
      "[ 0.4    -1.9498  1.6825] 10.47817708753032 0.8281262899999986\n",
      "[ 0.4    -1.9498  1.6625] 10.471345811411013 0.8012262899999987\n",
      "[ 0.4    -1.9498  1.6425] 10.46409600148726 0.7751262899999987\n",
      "[ 0.4    -1.9498  1.6225] 10.456387986964693 0.7498262899999987\n"
     ]
    }
   ],
   "source": [
    "# Fill buffer with samples collected ramdomly from environment\n",
    "buffer_len=5000\n",
    "tmax=500\n",
    "env.renderize=False\n",
    "if NEW_BUFFER:\n",
    "    exp_replay = rbt.PrioritizedReplayBuffer(buffer_len)\n",
    "    #Add Expert user experience\n",
    "    q_far=np.array([ 0., -0.8 ,  0. , -0.0698,  0.,  3.3825,  0.    ])\n",
    "    env.panda.q=q_far\n",
    "    env.scene.step()\n",
    "    for i in range(94):\n",
    "        a=[0,-1,0]\n",
    "        s=env.get_q()\n",
    "        pos,r,done,info=env.step(a)\n",
    "        exp_replay.add(s, a, r, pos, done)\n",
    "        print(pos,r,env.fitness())\n",
    "    for i in range(60):\n",
    "        a=[1,0,0]\n",
    "        s=env.get_q()\n",
    "        pos,r,done,info=env.step(a)\n",
    "        exp_replay.add(s, a, r, pos, done)\n",
    "        print(pos,r,env.fitness())\n",
    "    for i in range(88):\n",
    "        a=[0,0,-1]\n",
    "        s=env.get_q()\n",
    "        pos,r,done,info=env.step(a)\n",
    "        exp_replay.add(s, a, r, pos, done)\n",
    "        print(pos,r,env.fitness())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3242\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# exp_replay = ReplayBuffer(buffer_len)\n",
    "env.renderize=False\n",
    "\n",
    "if NEW_BUFFER:\n",
    "    \n",
    "    for i in range(50):\n",
    "        \n",
    "        state=env.reset()\n",
    "        # Play 100 runs of experience with 100 steps and  stop if reach 10**4 samples\n",
    "        rbt.play_and_record(state, agent, env, exp_replay, n_steps=60)\n",
    "        \n",
    "        if len(exp_replay) == buffer_len:\n",
    "            break\n",
    "    print(len(exp_replay))\n",
    "\n",
    "\n",
    "\n",
    "    with open('buffer.pickle', 'wb') as handle:\n",
    "        pickle.dump(exp_replay.buffer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "else:\n",
    "    exp_replay = rbt.PrioritizedReplayBuffer(buffer_len)\n",
    "    with open('buffer.pickle', 'rb') as handle:\n",
    "        exp_replay.buffer=pickle.load(handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def monitor_tensorboard():\n",
    "    %reload_ext tensorboard\n",
    "    %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 119095), started 1:28:59 ago. (Use '!kill 119095' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6b7e884c8cb7d40\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6b7e884c8cb7d40\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "monitor_tensorboard()\n",
    "tb=SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_total_steps=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup some parameters for training\n",
    "timesteps_per_epoch = 1\n",
    "batch_size = 64\n",
    "total_steps = 50* 10**3\n",
    "#total_steps = 10\n",
    "\n",
    "#init Optimizer\n",
    "opt = torch.optim.Adam(agent.parameters(), lr=1e-4)\n",
    "\n",
    "# set exploration epsilon \n",
    "start_epsilon = 1\n",
    "end_epsilon = 0.05\n",
    "eps_decay_final_step = percentage_of_total_steps*total_steps\n",
    "\n",
    "# setup some frequency for logging and updating target network\n",
    "loss_freq = 40\n",
    "refresh_target_network_freq = 100\n",
    "eval_freq = 1000\n",
    "\n",
    "# to clip the gradients\n",
    "max_grad_norm = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [13:54<00:00, 59.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer size = 5000, epsilon = 0.05000\n",
      "Frequency evaluation = 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env.renderize=False\n",
    "if TRAIN:\n",
    "    \n",
    "    state = env.reset()\n",
    "    tb.add_graph(agent.network, torch.tensor(state, device=device, dtype=torch.float32))\n",
    "    \n",
    "    for step in trange(total_steps + 1):\n",
    "        \n",
    "        \n",
    "        # reduce exploration as we progress\n",
    "        agent.epsilon = rbt.epsilon_schedule(start_epsilon, end_epsilon, step, eps_decay_final_step)\n",
    "\n",
    "        # take timesteps_per_epoch and update experience replay buffer\n",
    "        _, state = rbt.play_and_record(state, agent, env, exp_replay, timesteps_per_epoch)\n",
    "\n",
    "        \n",
    "        # train by sampling batch_size of data from experience replay\n",
    "        states, actions, rewards, next_states, done_flags, weights, idxs = exp_replay.sample(batch_size)\n",
    "        actions =[agent.get_action_index(i) for i in actions]\n",
    "        \n",
    "\n",
    "        # loss = <compute TD loss>\n",
    "\n",
    "        loss = rbt.compute_td_loss_priority_replay(agent, target_network, exp_replay,\n",
    "                           states, actions, rewards, next_states, done_flags, weights, idxs,              \n",
    "                           gamma=0.99,\n",
    "                           device=device)\n",
    "        tb.add_scalar(\"1/TD Loss\", loss, step)\n",
    "        loss.backward()\n",
    "        grad_norm = nn.utils.clip_grad_norm_(agent.parameters(), max_grad_norm)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        tb.add_scalar(\"2/Epsilon\", agent.epsilon,step)\n",
    "        if step % loss_freq == 0:\n",
    "            td_loss_history.append(loss.data.cpu().item())\n",
    "            tb.add_scalar(\"Loss\", loss, step)\n",
    "\n",
    "        if step % refresh_target_network_freq == 0:\n",
    "            # Load agent weights into target_network\n",
    "            target_network.load_state_dict(agent.state_dict())\n",
    "\n",
    "        if step % eval_freq == 0:\n",
    "            # eval the agent\n",
    "            m_reward=rbt.evaluate(env, agent, n_games=50, greedy=True, t_max=tmax)[0] \n",
    "            \n",
    "            tb.add_scalar(\"1/Mean reward per episode\", m_reward, step)\n",
    "            mean_rw_history.append(m_reward)\n",
    "            clear_output(True)\n",
    "            print(\"buffer size = %i, epsilon = %.5f\" %\n",
    "                (len(exp_replay), agent.epsilon))\n",
    "            print(f\"Frequency evaluation = {eval_freq}\")\n",
    "\n",
    "            # plt.figure(figsize=[16, 5])\n",
    "            # plt.subplot(1, 2, 1)\n",
    "            # plt.title(\"Mean reward per episode\")\n",
    "            # plt.plot(mean_rw_history)\n",
    "            # plt.grid()\n",
    "\n",
    "            assert not np.isnan(td_loss_history[-1])\n",
    "            # plt.subplot(1, 2, 2)\n",
    "            # plt.title(\"TD loss history (smoothened)\")\n",
    "            # plt.plot(rbt.smoothen(td_loss_history))\n",
    "            # plt.grid()\n",
    "            # plt.show()\n",
    "            \n",
    "    tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taniel/anaconda3/envs/RTB/lib/python3.10/site-packages/roboticstoolbox/robot/Link.py:1041: FutureWarning: base kwarg is deprecated, use pose instead\n",
      "  warn(\"base kwarg is deprecated, use pose instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final score:1083.9419201936398 in 299.0 steps\n",
      "[['', '']]\n",
      "Well done , Distance: 0.6399808624454344, Fitness: 0.006900000000000194\n",
      "collision False\n"
     ]
    }
   ],
   "source": [
    "env.renderize=True\n",
    "final_score,m_steps,infos = rbt.evaluate(env,agent, n_games=1, greedy=True, t_max=300)\n",
    "print(f'final score:{final_score} in {m_steps} steps')\n",
    "print(infos)\n",
    "print(f'Well done , Distance: {env.distance()}, Fitness: {env.fitness()}')\n",
    "print(f\"collision {env.detect_collision()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_AGENT=False\n",
    "SAVE_AGENT=False\n",
    "\n",
    "FILE_PREFIX=['mean_rw_history','td_loss_history']\n",
    "EXTENSION='.pickle'\n",
    "NAME=\"-reduced_network\"\n",
    "FILENAME=[]\n",
    "for i in FILE_PREFIX:\n",
    "    FILENAME.append(i+NAME+EXTENSION)\n",
    "\n",
    "\n",
    "if SAVE_AGENT:\n",
    "    torch.save(agent.state_dict(), 'model_panda_trained.pth')\n",
    "    for (i,j) in zip(FILENAME,FILE_PREFIX):\n",
    "        with open(i, 'wb') as handle:\n",
    "            pickle.dump(j, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47 -1.46  1.93] -0.31434354714937784 False ['', '']\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "qvalues = agent.get_qvalues([state])\n",
    "action = agent.actions_space[qvalues.argmax(axis=-1)[0]]\n",
    "state, r, done, info = env.step(action)\n",
    "print(state, r, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvalues = agent.get_qvalues([state])\n",
    "action = agent.actions_space[qvalues.argmax(axis=-1)[0]]\n",
    "state, r, done, _ = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got reward: -60.23543929349693\n",
      "Done , Distance: 0.11567246589957013\n",
      "collision False\n",
      "['', '']\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "reward = 0\n",
    "while True:\n",
    "    qvalues = agent.get_qvalues([state])\n",
    "    action = agent.actions_space[qvalues.argmax(axis=-1)[0]]\n",
    "    state, r, done, info = env.step(action)\n",
    "    reward += r\n",
    "    #print(reward)\n",
    "    if done or reward < -60:\n",
    "        print('Got reward: {}'.format(reward))\n",
    "        break\n",
    "print(f'Done , Distance: {env.distance()}')\n",
    "print(f\"collision {env.detect_collision()[0]}\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37.720524, 37.62541 , 37.7483  , 37.662205, 37.581844, 37.723557,\n",
       "        37.18852 , 37.282505, 37.045635, 37.559494, 37.64467 , 37.614708,\n",
       "        37.549328, 37.694244, 37.145237, 37.227955, 37.039345, 36.688076,\n",
       "        36.48168 , 37.024166, 36.7472  , 37.522846, 37.011032, 36.137203,\n",
       "        36.146122, 36.124207]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state=env.get_q()\n",
    "qvalues = agent.get_qvalues([state])\n",
    "qvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let us record a video of trained agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Animate learned policy\n",
    "# save_dir='./videos/'\n",
    "# #env = make_env(env_name)\n",
    "# generate_animation(env, agent, save_dir=save_dir)\n",
    "# [filepath] = glob.glob(os.path.join(save_dir, '*.mp4'))\n",
    "\n",
    "# display_animation(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "# Run this on another environment in OpenAI Gym\n",
    "# Create a robotic environment with more actions\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('RTB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "007c3d4ec7d1faff975b7b2e6628fd4907f6779597816faa5595ad19bf6f4797"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
